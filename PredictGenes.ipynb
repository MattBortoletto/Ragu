{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10000 genes\n",
      "Finished 20000 genes\n",
      "Finished 30000 genes\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "gene_file = 'hg19_gene_clean.fa'\n",
    "\n",
    "e = 0\n",
    "gene_seqs = []\n",
    "gene_ids = []\n",
    "for gene in SeqIO.parse('/home/ubuntu/data/' + gene_file, \n",
    "                        'fasta'):\n",
    "    \n",
    "    cutoff = 200\n",
    "    if len(str(gene.seq)) < cutoff:\n",
    "        continue\n",
    "\n",
    "    gene_ids.append(str(gene.id))\n",
    "    s_gene = str(gene.seq)[0:cutoff]\n",
    "    gene_seqs.append(s_gene)\n",
    "\n",
    "    e = e + 1\n",
    "    if e%10000 == 0:\n",
    "        print('Finished ' + str(e) + ' genes')\n",
    "\n",
    "def getKmers(sequence, size):\n",
    "    return [sequence[x:x+size].upper() for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "kmer = 10\n",
    "gene_texts = [' '.join(getKmers(i, kmer)) for i in gene_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[547859 642875 642876 ... 125875 110809  77277]\n",
      " [253351 294309 164774 ...  31487 125876 218639]\n",
      " [164781  61751 110810 ... 253371 218650 294330]\n",
      " ...\n",
      " [300782 349547 453994 ...  14457  10644  10929]\n",
      " [ 63780 142785 252925 ...  53054 543738 324349]\n",
      " [273128 360570 109937 ... 219163  82309 120347]]\n",
      "\n",
      "\n",
      "(35549, 191)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(gene_texts)\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(gene_texts)\n",
    "max_length = max([len(s.split()) for s in gene_texts])\n",
    "X_gene = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n",
    "\n",
    "print(X_gene)\n",
    "print('\\n')\n",
    "print(X_gene.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891013\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, MaxPooling1D, Flatten, Dropout, Embedding, Activation, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(944238, 10))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.load_weights(\"LSTM.weights.best.hdf5\")\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_predictions = model.predict_classes(X_gene)\n",
    "gene_predictions_prob = model.predict_proba(X_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_predictions_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gene_pred_df = pd.DataFrame({'Gene': gene_ids, \n",
    "                             'Predict': list(gene_predictions.flatten()), \n",
    "                             'Prob': list(gene_predictions_prob.flatten())})\n",
    "gene_pred_df = gene_pred_df.sort_values(['Prob'], ascending = False)\n",
    "gene_pred_df[(gene_pred_df['Predict'] == 1) & (gene_pred_df['Prob'] > 0.8)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
