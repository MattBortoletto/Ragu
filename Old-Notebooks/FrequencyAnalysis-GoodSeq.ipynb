{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import choice\n",
    "\n",
    "def weightedchoice(items): \n",
    "    return choice(\"\".join(x * y for x, y in items))\n",
    "\n",
    "DNA_intr = \"\"\n",
    "DNA_depl = \"\"\n",
    "\n",
    "for i in range(500001):\n",
    "    DNA_intr += weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)])\n",
    "    DNA_depl += weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)])\n",
    "    \n",
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"CCGCG\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "\n",
    "words = [\"CCGCG\", \"CGCGC\", \"GCGCC\", \"CGGCG\", \"CGGCC\"]\n",
    "\n",
    "#print(DNA_intr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_intr = DNA_intr.replace(\"CCGCG\", weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)]))\n",
    "DNA_intr = DNA_intr.replace(\"CGCGC\", weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)]))\n",
    "DNA_intr = DNA_intr.replace(\"GCGCC\", weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)]))\n",
    "DNA_intr = DNA_intr.replace(\"CGGCG\", weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)]))\n",
    "DNA_intr = DNA_intr.replace(\"CGGCC\", weightedchoice([(\"C\", 1), (\"G\", 1), (\"A\", 1), (\"T\", 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"CCGCG\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"CGCGC\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"GCGCC\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"CGGCG\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if DNA_intr[n:n+5] == \"CGGCC\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "freq_sort_intr = 0.0005196965286657252\n",
    "tot_changes = freq_sort_intr*len(DNA_intr)\n",
    "print(int(tot_changes/5))\n",
    "\n",
    "pos = np.random.randint(0, len(DNA_intr), int(len(DNA_intr)*freq_sort_intr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_str(string, str_to_insert, index):\n",
    "    return string[:index] + str_to_insert + string[index:]\n",
    "\n",
    "d = [None]*51\n",
    "i = 0\n",
    "for p in pos:\n",
    "    impw = np.random.choice([\"CCGCG\", \"CGCGC\", \"GCGCC\", \"CGGCG\", \"CGGCC\"], \n",
    "                                        p=[0.10554704, 0.11982444, 0.31040135, 0.10084078, 0.36338639])\n",
    "    #print(impw)\n",
    "    d[i] = insert_str(DNA_intr, impw, p)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"\"\n",
    "\n",
    "for i in range(51):\n",
    "    dna += d[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for n in range(len(DNA_intr)):\n",
    "    if dna[n:n+5] == \"CGGCC\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, LSTM, SimpleRNN, GRU\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, LSTM, SimpleRNN, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(DNA_complete)\n",
    "#X = tokenizer.texts_to_matrix(merge_texts, mode = 'freq')\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(DNA_complete)\n",
    "max_length = max([len(s.split()) for s in DNA_complete])\n",
    "X = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n",
    "\n",
    "print(X)\n",
    "print('\\n')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(s.split()) for s in merge_texts])\n",
    "print(max_length)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
